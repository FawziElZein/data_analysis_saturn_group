{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_data_handler import download_csv_to_dataframe\n",
    "from lookups import CsvUrlTweets,CsvUrlCoinsInfo,CsvUrlHistoricalData\n",
    "\n",
    "# Example usage:\n",
    "data_frame = download_csv_to_dataframe(CsvUrlHistoricalData.CRYPTO_TRANSACTIONS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_frame[~data_frame.index.duplicated(keep='first')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.to_csv('elon_musk_tweets.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['BTC-USD', 'ETH-USD', 'USDT-USD','BNB-USD','XRP-USD','LTC-USD','USDC-USD','DOGE-USD','TRX-USD','BUSD-USD']\n",
    "tickers[0][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahoofinancials import YahooFinancials\n",
    "import pandas as pd\n",
    "from pandas_data_handler import return_create_statement_from_df,return_insert_into_sql_statement_from_df\n",
    "from database_handler import execute_query,create_connection,return_data_as_df,parse_date_columns\n",
    "from lookups import InputTypes\n",
    "\n",
    "def get_coin_name(coin_symbol):\n",
    "\n",
    "    if coin_symbol == 'BTC':\n",
    "        return 'bitcoin'\n",
    "    if coin_symbol == 'ETH':\n",
    "        return 'ethereum'\n",
    "    if coin_symbol == 'USDT':\n",
    "        return 'tether'\n",
    "    if coin_symbol == 'BNB':\n",
    "        return 'binancecoin'\n",
    "    if coin_symbol == 'XRP':\n",
    "        return 'xrp'\n",
    "    if coin_symbol == 'LTC':\n",
    "        return 'litecoin'\n",
    "    if coin_symbol == 'USDC':\n",
    "        return 'usdcoin'\n",
    "    if coin_symbol == 'DOGE':\n",
    "        return 'dogecoin'\n",
    "    if coin_symbol == 'TRX':\n",
    "        return 'tron'\n",
    "    if coin_symbol == 'BUSD':\n",
    "        return 'binance_usd'\n",
    "    return 'unknown'\n",
    "\n",
    "def get_historical_prices(tickers, start_date, end_date):\n",
    "    data = {}\n",
    "    for ticker in tickers:\n",
    "        yahoo_financials = YahooFinancials(ticker)\n",
    "        historical_data = yahoo_financials.get_historical_price_data(start_date, end_date, \"daily\")\n",
    "        data[ticker] = historical_data[ticker]['prices']\n",
    "        print(data)\n",
    "    dfs = []\n",
    "    titles = []\n",
    "    for ticker, prices in data.items():\n",
    "        df = pd.DataFrame(prices)\n",
    "\n",
    "        df = df.drop('date', axis=1).set_index('formatted_date')\n",
    "        df['volume'] = df['volume'].astype(float)\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "        title = f'dim_{get_coin_name(ticker[:-4])}_price'\n",
    "        titles.append(title)\n",
    "        parse_date_columns(df)\n",
    "        create_query = return_create_statement_from_df(df,'dw_reporting',title)\n",
    "        execute_query(db_session=create_connection(),query=create_query)\n",
    "        insert_query = return_insert_into_sql_statement_from_df(df,'dw_reporting',title)\n",
    "        execute_query(db_session=create_connection(),query=insert_query)\n",
    "        dfs.append(df)\n",
    "    return dfs,titles\n",
    "\n",
    "tickers = ['BTC-USD', 'ETH-USD', 'USDT-USD','BNB-USD','XRP-USD','LTC-USD','USDC-USD','DOGE-USD','TRX-USD','BUSD-USD']\n",
    "start_date = '2008-01-01'\n",
    "end_date = '2023-03-1'\n",
    "\n",
    "dataframes = get_historical_prices(tickers,start_date,end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes[0].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hook: SQL Error=name 'SourceName' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Documents\\SE_Factory\\FSD\\Tech\\data_analysis_saturn_group\\database_handler.py:64: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return_dataframe = pd.read_sql_query(con= db_session, sql= file_executor)\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\OneDrive\\Documents\\SE_Factory\\FSD\\Tech\\data_analysis_saturn_group\\hook.py\", line 73, in execute_hook\n",
      "    create_insert_sql(db_session,SourceName.CRYPTO_DB,df_src_list,df_src_titles, ETLStep.HOOK, etl_date)\n",
      "NameError: name 'SourceName' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\OneDrive\\Documents\\SE_Factory\\FSD\\Tech\\data_analysis_saturn_group\\main.py\", line 6, in <module>\n",
      "    hook.execute_hook(df_src_list,df_src_titles)\n",
      "  File \"c:\\Users\\user\\OneDrive\\Documents\\SE_Factory\\FSD\\Tech\\data_analysis_saturn_group\\hook.py\", line 82, in execute_hook\n",
      "    raise Exception(\"Important Step Failed\")\n",
      "Exception: Important Step Failed\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1, 'name': 'Bitcoin', 'symbol': 'BTC', 'slug': 'bitcoin', 'num_market_pairs': 10479, 'date_added': '2010-07-13T00:00:00.000Z', 'tags': ['mineable', 'pow', 'sha-256', 'store-of-value', 'state-channel', 'coinbase-ventures-portfolio', 'three-arrows-capital-portfolio', 'polychain-capital-portfolio', 'binance-labs-portfolio', 'blockchain-capital-portfolio', 'boostvc-portfolio', 'cms-holdings-portfolio', 'dcg-portfolio', 'dragonfly-capital-portfolio', 'electric-capital-portfolio', 'fabric-ventures-portfolio', 'framework-ventures-portfolio', 'galaxy-digital-portfolio', 'huobi-capital-portfolio', 'alameda-research-portfolio', 'a16z-portfolio', '1confirmation-portfolio', 'winklevoss-capital-portfolio', 'usv-portfolio', 'placeholder-ventures-portfolio', 'pantera-capital-portfolio', 'multicoin-capital-portfolio', 'paradigm-portfolio', 'bitcoin-ecosystem', 'ftx-bankruptcy-estate'], 'max_supply': 21000000, 'circulating_supply': 19498018, 'total_supply': 19498018, 'infinite_supply': False, 'platform': None, 'cmc_rank': 1, 'self_reported_circulating_supply': None, 'self_reported_market_cap': None, 'tvl_ratio': None, 'last_updated': '2023-09-28T06:34:00.000Z', 'quote': {'USD': {'price': 26394.065509533448, 'volume_24h': 12649866314.135818, 'volume_change_24h': 73.3141, 'percent_change_1h': -0.21892416, 'percent_change_24h': 0.5871626, 'percent_change_7d': -2.30868741, 'percent_change_30d': 1.47919349, 'percent_change_60d': -9.85753092, 'percent_change_90d': -13.88924653, 'market_cap': 514631964398.0623, 'market_cap_dominance': 48.926, 'fully_diluted_market_cap': 554275375700.2, 'tvl': None, 'last_updated': '2023-09-28T06:34:00.000Z'}}}, {'id': 1027, 'name': 'Ethereum', 'symbol': 'ETH', 'slug': 'ethereum', 'num_market_pairs': 7448, 'date_added': '2015-08-07T00:00:00.000Z', 'tags': ['pos', 'smart-contracts', 'ethereum-ecosystem', 'coinbase-ventures-portfolio', 'three-arrows-capital-portfolio', 'polychain-capital-portfolio', 'binance-labs-portfolio', 'blockchain-capital-portfolio', 'boostvc-portfolio', 'cms-holdings-portfolio', 'dcg-portfolio', 'dragonfly-capital-portfolio', 'electric-capital-portfolio', 'fabric-ventures-portfolio', 'framework-ventures-portfolio', 'hashkey-capital-portfolio', 'kenetic-capital-portfolio', 'huobi-capital-portfolio', 'alameda-research-portfolio', 'a16z-portfolio', '1confirmation-portfolio', 'winklevoss-capital-portfolio', 'usv-portfolio', 'placeholder-ventures-portfolio', 'pantera-capital-portfolio', 'multicoin-capital-portfolio', 'paradigm-portfolio', 'injective-ecosystem', 'layer-1', 'ftx-bankruptcy-estate'], 'max_supply': None, 'circulating_supply': 120234937.00908716, 'total_supply': 120234937.00908716, 'infinite_supply': True, 'platform': None, 'cmc_rank': 2, 'self_reported_circulating_supply': None, 'self_reported_market_cap': None, 'tvl_ratio': None, 'last_updated': '2023-09-28T06:34:00.000Z', 'quote': {'USD': {'price': 1609.7778379794754, 'volume_24h': 6134736008.741306, 'volume_change_24h': 86.4766, 'percent_change_1h': -0.1175508, 'percent_change_24h': 1.13233489, 'percent_change_7d': -0.55465728, 'percent_change_30d': -2.17831278, 'percent_change_60d': -14.12335636, 'percent_change_90d': -14.23443335, 'market_cap': 193551536948.08673, 'market_cap_dominance': 18.4009, 'fully_diluted_market_cap': 193551536948.09, 'tvl': None, 'last_updated': '2023-09-28T06:34:00.000Z'}}}, {'id': 825, 'name': 'Tether USDt', 'symbol': 'USDT', 'slug': 'tether', 'num_market_pairs': 62895, 'date_added': '2015-02-25T00:00:00.000Z', 'tags': ['payments', 'stablecoin', 'asset-backed-stablecoin', 'avalanche-ecosystem', 'solana-ecosystem', 'arbitrum-ecosytem', 'moonriver-ecosystem', 'injective-ecosystem', 'bnb-chain', 'usd-stablecoin', 'optimism-ecosystem'], 'max_supply': None, 'circulating_supply': 83271216062.91978, 'total_supply': 86425711834.30376, 'platform': {'id': 1027, 'name': 'Ethereum', 'symbol': 'ETH', 'slug': 'ethereum', 'token_address': '0xdac17f958d2ee523a2206206994597c13d831ec7'}, 'infinite_supply': True, 'cmc_rank': 3, 'self_reported_circulating_supply': None, 'self_reported_market_cap': None, 'tvl_ratio': None, 'last_updated': '2023-09-28T06:34:00.000Z', 'quote': {'USD': {'price': 0.9991652755630885, 'volume_24h': 22383700482.44969, 'volume_change_24h': 46.9887, 'percent_change_1h': -0.01801458, 'percent_change_24h': -0.03677532, 'percent_change_7d': -0.09263849, 'percent_change_30d': -0.04489927, 'percent_change_60d': -0.09199332, 'percent_change_90d': -0.05849856, 'market_cap': 83201707543.98073, 'market_cap_dominance': 7.91, 'fully_diluted_market_cap': 86353570180.66, 'tvl': None, 'last_updated': '2023-09-28T06:34:00.000Z'}}}, {'id': 1839, 'name': 'BNB', 'symbol': 'BNB', 'slug': 'bnb', 'num_market_pairs': 1643, 'date_added': '2017-07-25T00:00:00.000Z', 'tags': ['marketplace', 'centralized-exchange', 'payments', 'smart-contracts', 'alameda-research-portfolio', 'multicoin-capital-portfolio', 'bnb-chain', 'layer-1', 'sec-security-token', 'alleged-sec-securities', 'celsius-bankruptcy-estate'], 'max_supply': None, 'circulating_supply': 153846955.24548742, 'total_supply': 153846955.24548742, 'infinite_supply': False, 'platform': None, 'cmc_rank': 4, 'self_reported_circulating_supply': None, 'self_reported_market_cap': None, 'tvl_ratio': None, 'last_updated': '2023-09-28T06:34:00.000Z', 'quote': {'USD': {'price': 211.96921517612805, 'volume_24h': 757726569.4639452, 'volume_change_24h': 29.7659, 'percent_change_1h': 0.03411205, 'percent_change_24h': -0.39920343, 'percent_change_7d': -0.7741826, 'percent_change_30d': -2.63572394, 'percent_change_60d': -12.42162743, 'percent_change_90d': -10.53821895, 'market_cap': 32610818360.622864, 'market_cap_dominance': 3.1003, 'fully_diluted_market_cap': 32610818360.62, 'tvl': None, 'last_updated': '2023-09-28T06:34:00.000Z'}}}, {'id': 52, 'name': 'XRP', 'symbol': 'XRP', 'slug': 'xrp', 'num_market_pairs': 1099, 'date_added': '2013-08-04T00:00:00.000Z', 'tags': ['medium-of-exchange', 'enterprise-solutions', 'arrington-xrp-capital-portfolio', 'galaxy-digital-portfolio', 'a16z-portfolio', 'pantera-capital-portfolio', 'ftx-bankruptcy-estate'], 'max_supply': 100000000000, 'circulating_supply': 53312364216, 'total_supply': 99988397127, 'infinite_supply': False, 'platform': None, 'cmc_rank': 5, 'self_reported_circulating_supply': None, 'self_reported_market_cap': None, 'tvl_ratio': None, 'last_updated': '2023-09-28T06:34:00.000Z', 'quote': {'USD': {'price': 0.49568449865076825, 'volume_24h': 777499049.0858113, 'volume_change_24h': 4.534, 'percent_change_1h': -0.34012574, 'percent_change_24h': -0.40798122, 'percent_change_7d': -3.19016041, 'percent_change_30d': -4.33890985, 'percent_change_60d': -30.18209834, 'percent_change_90d': 4.22647168, 'market_cap': 26426112528.295116, 'market_cap_dominance': 2.5123, 'fully_diluted_market_cap': 49568449865.08, 'tvl': None, 'last_updated': '2023-09-28T06:34:00.000Z'}}}]\n",
      "BTC 26394.065509533448\n",
      "ETH 1609.7778379794754\n",
      "USDT 0.9991652755630885\n",
      "BNB 211.96921517612805\n",
      "XRP 0.49568449865076825\n"
     ]
    }
   ],
   "source": [
    "!python bitcoin.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"sentiment\")\n",
    "def analyze_sentiment(text):\n",
    "  \n",
    "  doc = nlp(text)\n",
    "  sentiment_scores = doc._.sentiment\n",
    "  compound_score = sentiment_scores[\"compound\"]\n",
    "\n",
    "  if compound_score >= 0.05:\n",
    "    sentiment = \"positive\"\n",
    "  elif compound_score <= -0.05:\n",
    "    sentiment = \"negative\"\n",
    "  else:\n",
    "    sentiment = \"neutral\"\n",
    "\n",
    "  return sentiment, compound_score\n",
    "\n",
    "texts = [\n",
    "  \"I love this product! It's amazing.\",\n",
    "  \"This movie is terrible.\",\n",
    "  \"The weather today is okay.\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "  sentiment, compound_score = analyze_sentiment(text)\n",
    "  print(f\"Text: {text}\")\n",
    "  print(f\"Sentiment: {sentiment} (Compound Score: {compound_score})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load a pre-trained transformer model for sentiment analysis (e.g., BERT)\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\", model=\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "# Example text\n",
    "text = \"The weather today is okay.\"\n",
    "\n",
    "# Tokenize the text using spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Convert spaCy tokens back to a text string\n",
    "tokenized_text = \" \".join([token.text for token in doc])\n",
    "\n",
    "\n",
    "# Perform sentiment analysis using the transformer model\n",
    "sentiment_results = sentiment_analysis(tokenized_text)\n",
    "\n",
    "# Extract the sentiment label and score\n",
    "sentiment_label = sentiment_results[0][\"label\"]\n",
    "sentiment_score = sentiment_results[0][\"score\"]\n",
    "\n",
    "print(sentiment_results)\n",
    "print(f\"Sentiment Label: {sentiment_label}\")\n",
    "print(f\"Sentiment Score: {sentiment_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\", model=\"bert-base-uncased\")\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "  \n",
    "  doc = nlp(text)\n",
    "  tokenized_text = \" \".join([token.text for token in doc])\n",
    "  sentiment_results = sentiment_analysis(tokenized_text)\n",
    "  # sentiment_scores = doc._.sentiment\n",
    "  sentiment_label = sentiment_results[0][\"label\"]\n",
    "  sentiment_score = sentiment_results[0][\"score\"]\n",
    "\n",
    "  # compound_score = sentiment_scores[\"compound\"]\n",
    "\n",
    "  # if compound_score >= 0.05:\n",
    "  #   sentiment = \"positive\"\n",
    "  # elif compound_score <= -0.05:\n",
    "  #   sentiment = \"negative\"\n",
    "  # else:\n",
    "  #   sentiment = \"neutral\"\n",
    "\n",
    "  return sentiment_label, sentiment_score\n",
    "\n",
    "texts = [\n",
    "  \"I love this product! It's amazing.\",\n",
    "  \"This movie is terrible.\",\n",
    "  \"The weather today is okay.\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "  # sentiment, compound_score = analyze_sentiment(text)\n",
    "  sentiment, compound_score = analyze_sentiment(text)\n",
    "\n",
    "  print(f\"Text: {text}\")\n",
    "  print(f\"Sentiment: {sentiment} (Compound Score: {compound_score})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load a pre-trained transformer model for sentiment analysis (e.g., GPT2)\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\", model=\"gpt2\")\n",
    "\n",
    "\n",
    "# Example text\n",
    "text = \"This movie is terrible.\"\n",
    "\n",
    "# Tokenize the text using spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Convert spaCy tokens back to a text string\n",
    "tokenized_text = \" \".join([token.text for token in doc])\n",
    "\n",
    "\n",
    "# Perform sentiment analysis using the transformer model\n",
    "sentiment_results = sentiment_analysis(tokenized_text)\n",
    "\n",
    "# Extract the sentiment label and score\n",
    "sentiment_label = sentiment_results[0][\"label\"]\n",
    "sentiment_score = sentiment_results[0][\"score\"]\n",
    "\n",
    "print(sentiment_results)\n",
    "print(f\"Sentiment Label: {sentiment_label}\")\n",
    "print(f\"Sentiment Score: {sentiment_score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "def analyze_sentiment_with_gpt2(text):\n",
    "    # Define prompts for different sentiments\n",
    "    positive_prompt = \"This movie is wonderful\"\n",
    "    negative_prompt = \"This movie is terrible\"\n",
    "\n",
    "    # Generate text with GPT-2 based on input text\n",
    "    generated_text_positive = text_generator(positive_prompt + text)[0][\"generated_text\"]\n",
    "    generated_text_negative = text_generator(negative_prompt + text)[0][\"generated_text\"]\n",
    "\n",
    "    # Analyze the generated text to infer sentiment\n",
    "    positive_score = analyze_sentiment(generated_text_positive)\n",
    "    negative_score = analyze_sentiment(generated_text_negative)\n",
    "\n",
    "    # Determine overall sentiment based on the scores\n",
    "    if positive_score > negative_score:\n",
    "        sentiment = \"Positive\"\n",
    "    elif positive_score < negative_score:\n",
    "        sentiment = \"Negative\"\n",
    "    else:\n",
    "        sentiment = \"Neutral\"\n",
    "\n",
    "    return sentiment\n",
    "\n",
    "# Example text\n",
    "text = \"I really enjoyed the movie. It was fantastic!\"\n",
    "\n",
    "# Analyze sentiment using GPT-2\n",
    "sentiment = analyze_sentiment_with_gpt2(text)\n",
    "print(f\"Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lookups import CsvUrlTweets,CsvUrlHistoricalData\n",
    "from pandas_data_handler import get_online_csv_into_df_list\n",
    "\n",
    "df_list,df_titles = get_online_csv_into_df_list(CsvUrlTweets,CsvUrlHistoricalData)\n",
    "df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[1].iloc[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prehook import execute_prehook\n",
    "\n",
    "execute_prehook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests                    # for \"get\" request to API\n",
    "import json                        # parse json into a list\n",
    "import pandas as pd                # working with data frames\n",
    "import datetime as dt              # working with dates\n",
    "import matplotlib.pyplot as plt    # plot data\n",
    "# import qgrid                       # display dataframe in notebooks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binance_bars(symbol, interval, startTime, endTime):\n",
    " \n",
    "    url = \"https://api.binance.com/api/v3/klines\"\n",
    " \n",
    "    startTime = str(int(startTime.timestamp() * 1000))\n",
    "    endTime = str(int(endTime.timestamp() * 1000))\n",
    "    limit = '1000'\n",
    " \n",
    "    req_params = {\"symbol\" : symbol, 'interval' : interval, 'startTime' : startTime, 'endTime' : endTime, 'limit' : limit}\n",
    " \n",
    "    df = pd.DataFrame(json.loads(requests.get(url, params = req_params).text))\n",
    " \n",
    "    if (len(df.index) == 0):\n",
    "        return None\n",
    "     \n",
    "    df = df.iloc[:, 0:6]\n",
    "    df.columns = ['datetime', 'open', 'high', 'low', 'close', 'volume']\n",
    " \n",
    "    df.open      = df.open.astype(\"float\")\n",
    "    df.high      = df.high.astype(\"float\")\n",
    "    df.low       = df.low.astype(\"float\")\n",
    "    df.close     = df.close.astype(\"float\")\n",
    "    df.volume    = df.volume.astype(\"float\")\n",
    "    \n",
    "    df['adj_close'] = df['close']\n",
    "     \n",
    "    df.index = [dt.datetime.fromtimestamp(x / 1000.0) for x in df.datetime]\n",
    " \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_binance_bars('ETHBTC', '1h', dt.datetime(2020, 1, 1), dt.datetime(2020, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This example uses Python 2.7 and the python-request library.\n",
    "\n",
    "from requests import Request, Session\n",
    "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
    "import json\n",
    "\n",
    "url = 'https://sandbox-api.coinmarketcap.com/v1/cryptocurrency/listings/latest'\n",
    "parameters = {\n",
    "  'start':'1',\n",
    "  'limit':'5000',\n",
    "  'convert':'USD'\n",
    "}\n",
    "headers = {\n",
    "  'Accepts': 'application/json',\n",
    "  'X-CMC_PRO_API_KEY': 'b54bcf4d-1bca-4e8e-9a24-22ff2c3d462c',\n",
    "}\n",
    "\n",
    "session = Session()\n",
    "session.headers.update(headers)\n",
    "\n",
    "try:\n",
    "  response = session.get(url, params=parameters)\n",
    "  data = json.loads(response.text)\n",
    "  print(data)\n",
    "except (ConnectionError, Timeout, TooManyRedirects) as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apikey\n",
    "import requests\n",
    "\n",
    "headers = {\n",
    "    'X-CMC_PRO_API_KEY': '3961abc5-31d6-40e9-8ebb-018bbff4745f',\n",
    "    'Accepts': 'application/json'\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'start': '1',\n",
    "    'limit': '10',\n",
    "    'convert': 'USD'\n",
    "}\n",
    "\n",
    "url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/quotes/historical?id=1&time_start=2021-09-01T00:00:00Z&time_end=2021-09-30T23:59:59Z&interval=daily&convert=USD'\n",
    "\n",
    "json = requests.get(url,params = params,headers = headers).json()\n",
    "\n",
    "print(json)\n",
    "# coins = json['data']\n",
    "\n",
    "# for x in coins:\n",
    "#     print(x['symbol'],x['quote']['USD']['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# replace the \"demo\" apikey below with your own key from https://www.alphavantage.co/support/#api-key\n",
    "url = 'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=BTC&interval=5min&apikey=IBC6UTTQ70KJWNSU'\n",
    "r = requests.get(url)\n",
    "data = r.json()\n",
    "\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "daily_time_series = data.get('Time Series (Daily)')\n",
    "\n",
    "# Convert the daily time series data to a DataFrame\n",
    "df = pd.DataFrame.from_dict(daily_time_series, orient='index')\n",
    "df.reset_index(inplace=True)\n",
    "df.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "# Convert date strings to datetime objects\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Print the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KPI:\n",
    "1- Variance/Standard deviation per month\n",
    "2- Top 5 coins per month and their average monthly Worth\n",
    "3- Trading Volumn\n",
    "4- Volume and Price Correlation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Date.min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sefactory_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
