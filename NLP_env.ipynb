{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import NaN\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from yahoofinancials import YahooFinancials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # remove punctuation and special characters\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)  # r'[^\\w\\s]' : matches any character that is not a word character (alphanumeric or underscore) or a whitespace character\n",
    "        # convert to lowercase\n",
    "        text = text.lower()\n",
    "        # tokenize text\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        # remove stop words\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "        # lemmatize text\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "        # join tokens back into text\n",
    "        text = ' '.join(tokens)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file into a DataFrame\n",
    "df = pd.read_csv(r\"C:\\Users\\Lenovo\\Desktop\\dataset_52-person-from-2021-02-05_2023-06-12_21-34-17-266_with_sentiment.csv\")\n",
    "\n",
    "# Remove rows with \"na\" values\n",
    "df = df.dropna(subset=['full_text'])\n",
    "\n",
    "# # Fill missing values in 'full_text' column with an empty string\n",
    "df['full_text'] = df['full_text'].fillna('')\n",
    "# # to lower text\n",
    "df['full_text'] = df['full_text'].str.lower()\n",
    "# # Preprocess the 'full_text' column\n",
    "df['clean_text'] = df['full_text'].apply(preprocess_text)\n",
    "# # Filter the DataFrame to keep rows where \"created_at\" is greater than or equal to 2021-01-01\n",
    "import datetime\n",
    "# #Convert the \"created_at\" column to datetime format\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "# ##add importance_coefficient per tweets\n",
    "df['importance_coefficient'] = df['retweet_count'] + 2 * df['favorite_count'] + 0.5 * df['reply_count']\n",
    "# # Find the minimum and maximum values of the importance coefficient\n",
    "min_value = df['importance_coefficient'].min()\n",
    "max_value = df['importance_coefficient'].max()\n",
    "\n",
    "# # Normalize the importance coefficient\n",
    "df['importance_coefficient_normalized'] = (df['importance_coefficient'] - min_value) / (max_value - min_value)\n",
    "# # Sort the DataFrame based on the \"created_at\" column in ascending order\n",
    "df = df.sort_values('created_at', ascending=True)\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "df.head()\n",
    "df.loc[df[\"created_at\"]=='1/1/2023']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Vader Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(df):\n",
    "    # Create a copy of the input DataFrame\n",
    "    df_selected = df.copy()\n",
    "\n",
    "    # Initialize the VADER sentiment analyzer\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # Calculate sentiment scores and add them to the DataFrame\n",
    "    df_selected['scores'] = df_selected['full_text'].apply(lambda description: sid.polarity_scores(description))\n",
    "    df_selected['compound'] = df_selected['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "    \n",
    "    # Create a new column for sentiment_type and classify based on the compound score\n",
    "    df_selected['sentiment_type'] = df_selected['compound'].apply(lambda avg_compound: 'POSITIVE' if avg_compound > 0 else 'NEUTRAL' if avg_compound == 0 else 'NEGATIVE')\n",
    "\n",
    "    return df_selected\n",
    "sentiment_df=analyze_sentiment(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def crypto_sentiment(df, coin_symbol):\n",
    "    df = df[df[\"new_coins\"].str.contains(f\"({coin_symbol})\")].copy()\n",
    "    df = df[(df[\"created_at\"] >= \"2023-01-01\") & (df[\"created_at\"] <= \"2023-06-12\")].sort_values(by=\"created_at\", ascending=True)\n",
    "    sentiment_df = df.groupby(df['created_at'].dt.date)['compound'].mean().reset_index()\n",
    "\n",
    "    def classify_sentiment(avg_compound):\n",
    "        if avg_compound > 0:\n",
    "            return 'Positive'\n",
    "        elif avg_compound < 0:\n",
    "            return 'Negative'\n",
    "        else:\n",
    "            return 'Neutral'\n",
    "\n",
    "    sentiment_df['sentiment_type'] = sentiment_df['compound'].apply(classify_sentiment)\n",
    "\n",
    "    return sentiment_df\n",
    "\n",
    "\n",
    "\n",
    "btc_sentiment=crypto_sentiment_result = crypto_sentiment(sentiment_df, \"(btc)\")\n",
    "eth_sentiment=crypto_sentiment(sentiment_df, \"(eth)\")\n",
    "bnb_sentiment=crypto_sentiment(sentiment_df, \"(bnb)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_prices(tickers, start_date, end_date):\n",
    "    data = {}\n",
    "    for ticker in tickers:\n",
    "        yahoo_financials = YahooFinancials(ticker)\n",
    "        historical_data = yahoo_financials.get_historical_price_data(start_date, end_date, \"daily\")\n",
    "        data[ticker] = historical_data[ticker]['prices']\n",
    "    dfs = []\n",
    "    for ticker, prices in data.items():\n",
    "        df = pd.DataFrame(prices)\n",
    "        df = df.drop('date', axis=1).set_index('formatted_date')\n",
    "        df.columns = [f\"{ticker}_close\", f\"{ticker}_high\", f\"{ticker}_low\", f\"{ticker}_open\", f\"{ticker}_volume\", f\"{ticker}_adjclose\"]\n",
    "        df['formatted_date'] = pd.to_datetime(df.index) # Add formatted_date column\n",
    "        dfs.append(df)\n",
    "    merged_df = pd.concat(dfs, axis=1)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['BTC-USD', 'ETH-USD', 'BNB-USD','XMR-USD','MATIC-USD','XRP-USD','DAI-USD','DOT-USD']\n",
    "start_date = '2021-2-1'\n",
    "end_date = '2023-06-12'\n",
    "\n",
    "btc_df = get_historical_prices(tickers, start_date, end_date)\n",
    "# Move formatted_date column to the first position\n",
    "btc_df = btc_df[[\"formatted_date\"] + [col for col in btc_df.columns if col != \"formatted_date\"]]\n",
    "# Delete duplicate formatted_date columns\n",
    "btc_df = btc_df.loc[:, ~btc_df.columns.duplicated()]\n",
    "print(btc_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare the data\n",
    "df_draw = btc_df[['formatted_date', 'XRP-USD_volume', 'ETH-USD_volume', 'BTC-USD_volume','XMR-USD_volume'\n",
    ",'DAI-USD_volume','DOT-USD_volume']]\n",
    "df_draw['formatted_date'] = pd.to_datetime(df_draw['formatted_date'], format='%Y-%m-%d %I-%p')\n",
    "df_draw.set_index('formatted_date', inplace=True)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 6))  # Set the figure size to 12 inches wide and 6 inches high\n",
    "plt.plot(df_draw.index, df_draw['XRP-USD_volume'], label='Ripple')\n",
    "plt.plot(df_draw.index, df_draw['ETH-USD_volume'], label='ETH')\n",
    "plt.plot(df_draw.index, df_draw['BTC-USD_volume'], label='BTC')\n",
    "plt.plot(df_draw.index, df_draw['XMR-USD_volume'], label='Monero')\n",
    "plt.plot(df_draw.index, df_draw['DOT-USD_volume'], label='Polkadot')\n",
    "#plt.plot(df_draw.index, df_draw['DAI-USD_volume'], label='Dai')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volume')\n",
    "plt.title('Cryptocurrency Volume Over Time')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_selected = btc_df.iloc[:, :7]\n",
    "btc_selected = btc_selected.round(0)\n",
    "btc_selected['formatted_date'] = btc_selected.index\n",
    "\n",
    "btc_selected.head()\n",
    "#---ETH-selected------------\n",
    "eth_selected = btc_df.iloc[:, 7:13]\n",
    "eth_selected = eth_selected.round(0)\n",
    "eth_selected['formatted_date'] = eth_selected.index\n",
    "\n",
    "eth_selected\n",
    "#--BNB-selected------------\n",
    "bnb_selected = btc_df.iloc[:, 13:19]\n",
    "bnb_selected = bnb_selected.round(0)\n",
    "bnb_selected['formatted_date'] = bnb_selected.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate price changes\n",
    "btc_selected['price_changes'] = btc_selected['BTC-USD_close'].diff()\n",
    "btc_selected['price_changes'] = btc_selected['price_changes'].apply(lambda x: 'positive' if x > 0 else 'negative' if x < 0 else 'neutral')\n",
    "\n",
    "# Calculate price changes\n",
    "eth_selected['price_changes'] = eth_selected['ETH-USD_close'].diff()\n",
    "eth_selected['price_changes'] = eth_selected['price_changes'].apply(lambda x: 'positive' if x > 0 else 'negative' if x < 0 else 'neutral')\n",
    "eth_selected\n",
    "# Calculate price changes\n",
    "bnb_selected['price_changes'] = bnb_selected['BNB-USD_close'].diff()\n",
    "bnb_selected['price_changes'] = bnb_selected['price_changes'].apply(lambda x: 'positive' if x > 0 else 'negative' if x < 0 else 'neutral')\n",
    "bnb_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change columns name\n",
    "def remove_chars_before_underscore(df):\n",
    "    df.columns = df.columns.str.split('_').str[-1]\n",
    "remove_chars_before_underscore(btc_selected)\n",
    "remove_chars_before_underscore(eth_selected)\n",
    "remove_chars_before_underscore(bnb_selected)\n",
    "btc_selected\n",
    "eth_selected\n",
    "bnb_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add sentimeni type and compund to dataframe\n",
    "bnb_selected['date'] = pd.to_datetime(bnb_selected['date'])\n",
    "bnb_sentiment['created_at'] = pd.to_datetime(bnb_sentiment['created_at'])\n",
    "\n",
    "# Perform left merge on 'date' and 'created_at' columns\n",
    "bnb_selected = pd.merge(bnb_selected, bnb_sentiment[['created_at', 'compound', 'sentiment_type']],\n",
    "                     left_on='date', right_on='created_at', how='left')\n",
    "\n",
    "# Drop the redundant 'created_at' column\n",
    "bnb_selected = bnb_selected.drop('created_at', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# add sentimeni type and compund to dataframe\n",
    "eth_selected['date'] = pd.to_datetime(eth_selected['date'])\n",
    "eth_sentiment['created_at'] = pd.to_datetime(eth_sentiment['created_at'])\n",
    "\n",
    "# Perform left merge on 'date' and 'created_at' columns\n",
    "eth_selected = pd.merge(eth_selected, eth_sentiment[['created_at', 'compound', 'sentiment_type']],\n",
    "                     left_on='date', right_on='created_at', how='left')\n",
    "\n",
    "# Drop the redundant 'created_at' column\n",
    "eth_selected = eth_selected.drop('created_at', axis=1)\n",
    "\n",
    "eth_selected\n",
    "\n",
    "## add sentimeni type and compund to dataframe\n",
    "btc_selected['date'] = pd.to_datetime(btc_selected['date'])\n",
    "btc_sentiment['created_at'] = pd.to_datetime(btc_sentiment['created_at'])\n",
    "\n",
    "# Perform left merge on 'date' and 'created_at' columns\n",
    "btc_selected = pd.merge(btc_selected, btc_sentiment[['created_at', 'compound', 'sentiment_type']],\n",
    "                     left_on='date', right_on='created_at', how='left')\n",
    "\n",
    "# Drop the redundant 'created_at' column\n",
    "btc_selected = btc_selected.drop('created_at', axis=1)\n",
    "\n",
    "btc_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the top row\n",
    "bnb_selected = bnb_selected.iloc[1:]\n",
    "# Output the merged dataframe\n",
    "bnb_selected\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth_selected.to_csv(r\"C:\\Users\\Lenovo\\Desktop\\Saturn project\\sentiment\\bnb_selected_with_sentiment_2023_01_02_2023_06_12.csv\")\n",
    "btc_selected.to_csv(r\"C:\\Users\\Lenovo\\Desktop\\Saturn project\\sentiment\\btc_selected_with_sentiment_2023_01_02_2023_06_12.csv\")\n",
    "bnb_selected.to_csv(r\"C:\\Users\\Lenovo\\Desktop\\Saturn project\\sentiment\\bnb_selected_with_sentiment_2023_01_02_2023_06_12.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      close    high     low    open       volume  adjclose       date  \\\n",
      "0    1203.0  1193.0  1197.0  1201.0   2399674550    1201.0 2023-01-01   \n",
      "1    1220.0  1195.0  1201.0  1215.0   3765758498    1215.0 2023-01-02   \n",
      "2    1219.0  1207.0  1215.0  1215.0   3392972131    1215.0 2023-01-03   \n",
      "3    1265.0  1213.0  1215.0  1257.0   6404416893    1257.0 2023-01-04   \n",
      "4    1259.0  1245.0  1256.0  1250.0   4001786456    1250.0 2023-01-05   \n",
      "..      ...     ...     ...     ...          ...       ...        ...   \n",
      "158  1861.0  1830.0  1833.0  1846.0   4536041931    1846.0 2023-06-08   \n",
      "159  1855.0  1829.0  1846.0  1840.0   4610831509    1840.0 2023-06-09   \n",
      "160  1845.0  1721.0  1840.0  1752.0  10788500406    1752.0 2023-06-10   \n",
      "161  1777.0  1741.0  1753.0  1753.0   4559112981    1753.0 2023-06-11   \n",
      "162  1758.0  1723.0  1753.0  1743.0   6031384958    1743.0 2023-06-12   \n",
      "\n",
      "      changes  compound sentiment_type  \n",
      "0     neutral  0.199350       Positive  \n",
      "1    positive  0.214500       Positive  \n",
      "2    negative  0.000000        Neutral  \n",
      "3    positive -0.111800       Negative  \n",
      "4    negative -0.273200       Negative  \n",
      "..        ...       ...            ...  \n",
      "158  negative  0.273955       Positive  \n",
      "159  negative  0.372863       Positive  \n",
      "160  negative  0.245803       Positive  \n",
      "161  negative  0.235794       Positive  \n",
      "162  negative  0.113497       Positive  \n",
      "\n",
      "[163 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(eth_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
